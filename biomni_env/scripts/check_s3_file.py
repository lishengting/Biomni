#!/usr/bin/env python3
"""
S3æ–‡ä»¶å¤§å°æ£€æŸ¥å·¥å…·
ç›´æ¥æŸ¥è¯¢S3å­˜å‚¨æ¡¶ä¸­ç‰¹å®šæ–‡ä»¶çš„å¤§å°å’Œå¯è®¿é—®æ€§ï¼Œæ”¯æŒä¸‹è½½å’Œæ–­ç‚¹ç»­ä¼ 
"""

import requests
import os
import sys
from urllib.parse import urljoin
from typing import Dict, List, Tuple, Optional, Any
import time
import hashlib

def check_file_size(s3_bucket_url: str, file_path: str) -> Dict[str, Any]:
    """
    æ£€æŸ¥S3å­˜å‚¨æ¡¶ä¸­ç‰¹å®šæ–‡ä»¶çš„å¤§å°å’Œå¯è®¿é—®æ€§
    
    Args:
        s3_bucket_url: S3å­˜å‚¨æ¡¶çš„åŸºç¡€URL (e.g., "https://biomni-release.s3.amazonaws.com")
        file_path: æ–‡ä»¶åœ¨å­˜å‚¨æ¡¶ä¸­çš„è·¯å¾„ (e.g., "data_lake/gene_info.parquet")
        
    Returns:
        åŒ…å«æ–‡ä»¶ä¿¡æ¯çš„å­—å…¸
    """
    
    # æ„å»ºå®Œæ•´çš„æ–‡ä»¶URL
    file_url = urljoin(s3_bucket_url + "/", file_path)
    
    print(f"ğŸ” æ£€æŸ¥æ–‡ä»¶: {file_path}")
    print(f"ğŸ“¡ URL: {file_url}")
    
    try:
        # å‘é€HEADè¯·æ±‚æ¥è·å–æ–‡ä»¶ä¿¡æ¯ï¼ˆä¸ä¸‹è½½å†…å®¹ï¼‰
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        }
        
        response = requests.head(file_url, headers=headers, timeout=30)
        
        result = {
            "file_path": file_path,
            "url": file_url,
            "status_code": response.status_code,
            "accessible": False,
            "size_bytes": 0,
            "size_mb": 0,
            "content_type": "",
            "last_modified": "",
            "etag": "",
            "error": None
        }
        
        if response.status_code == 200:
            # æ–‡ä»¶å­˜åœ¨ä¸”å¯è®¿é—®
            result["accessible"] = True
            
            # è·å–æ–‡ä»¶å¤§å°
            content_length = response.headers.get('content-length')
            if content_length:
                result["size_bytes"] = int(content_length)
                result["size_mb"] = round(int(content_length) / (1024 * 1024), 2)
            
            # è·å–å…¶ä»–ä¿¡æ¯
            result["content_type"] = response.headers.get('content-type', '')
            result["last_modified"] = response.headers.get('last-modified', '')
            result["etag"] = response.headers.get('etag', '')
            
            print(f"âœ… æ–‡ä»¶å¯è®¿é—®")
            print(f"   å¤§å°: {format_file_size(result['size_bytes'])}")
            print(f"   ç±»å‹: {result['content_type']}")
            if result['last_modified']:
                print(f"   ä¿®æ”¹æ—¶é—´: {result['last_modified']}")
                
        elif response.status_code == 404:
            result["error"] = "æ–‡ä»¶ä¸å­˜åœ¨"
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨ (404)")
        elif response.status_code == 403:
            result["error"] = "è®¿é—®è¢«æ‹’ç»"
            print(f"âŒ è®¿é—®è¢«æ‹’ç» (403)")
        else:
            result["error"] = f"HTTPé”™è¯¯: {response.status_code}"
            print(f"âŒ HTTPé”™è¯¯: {response.status_code}")
            
        return result
        
    except requests.exceptions.Timeout:
        error_msg = "è¯·æ±‚è¶…æ—¶"
        print(f"âŒ {error_msg}")
        return {
            "file_path": file_path,
            "url": file_url,
            "status_code": None,
            "accessible": False,
            "size_bytes": 0,
            "size_mb": 0,
            "error": error_msg
        }
    except requests.exceptions.RequestException as e:
        error_msg = f"è¯·æ±‚å¼‚å¸¸: {e}"
        print(f"âŒ {error_msg}")
        return {
            "file_path": file_path,
            "url": file_url,
            "status_code": None,
            "accessible": False,
            "size_bytes": 0,
            "size_mb": 0,
            "error": error_msg
        }
    except Exception as e:
        error_msg = f"æœªçŸ¥é”™è¯¯: {e}"
        print(f"âŒ {error_msg}")
        return {
            "file_path": file_path,
            "url": file_url,
            "status_code": None,
            "accessible": False,
            "size_bytes": 0,
            "size_mb": 0,
            "error": error_msg
        }

def download_file_with_resume(s3_bucket_url: str, file_path: str, local_dir: str = ".", chunk_size: int = 8192, max_retries: int = 3, retry_delay: float = 5.0) -> Dict[str, Any]:
    """
    ä¸‹è½½æ–‡ä»¶ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œè‡ªåŠ¨é‡è¯•
    
    Args:
        s3_bucket_url: S3å­˜å‚¨æ¡¶çš„åŸºç¡€URL
        file_path: æ–‡ä»¶åœ¨å­˜å‚¨æ¡¶ä¸­çš„è·¯å¾„
        local_dir: æœ¬åœ°ä¿å­˜ç›®å½•
        chunk_size: ä¸‹è½½å—å¤§å°
        max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        retry_delay: é‡è¯•é—´éš”ï¼ˆç§’ï¼‰
        
    Returns:
        ä¸‹è½½ç»“æœå­—å…¸
    """
    
    # æ„å»ºå®Œæ•´çš„æ–‡ä»¶URL
    file_url = urljoin(s3_bucket_url + "/", file_path)
    
    # ç¡®å®šæœ¬åœ°æ–‡ä»¶è·¯å¾„
    filename = os.path.basename(file_path)
    local_file_path = os.path.join(local_dir, filename)
    temp_file_path = local_file_path + ".tmp"
    
    print(f"ğŸ“¥ å¼€å§‹ä¸‹è½½æ–‡ä»¶: {file_path}")
    print(f"ğŸ“¡ URL: {file_url}")
    print(f"ğŸ’¾ æœ¬åœ°è·¯å¾„: {local_file_path}")
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(local_dir, exist_ok=True)
    
    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¸´æ—¶æ–‡ä»¶ï¼ˆæ–­ç‚¹ç»­ä¼ ï¼‰
    resume_pos = 0
    if os.path.exists(temp_file_path):
        resume_pos = os.path.getsize(temp_file_path)
        print(f"ğŸ”„ å‘ç°ä¸´æ—¶æ–‡ä»¶ï¼Œä» {format_file_size(resume_pos)} å¤„ç»§ç»­ä¸‹è½½")
    
    # é‡è¯•é€»è¾‘
    for retry_count in range(max_retries + 1):
        try:
            # é¦–å…ˆæ£€æŸ¥æ–‡ä»¶ä¿¡æ¯
            file_info = check_file_size(s3_bucket_url, file_path)
            if not file_info["accessible"]:
                return {
                    "success": False,
                    "error": file_info["error"],
                    "file_path": file_path,
                    "local_path": local_file_path
                }
            
            total_size = file_info["size_bytes"]
            
            # å¦‚æœæ–‡ä»¶å·²å®Œæ•´ä¸‹è½½ï¼Œç›´æ¥è¿”å›
            if os.path.exists(local_file_path) and os.path.getsize(local_file_path) == total_size:
                print(f"âœ… æ–‡ä»¶å·²å®Œæ•´ä¸‹è½½: {local_file_path}")
                return {
                    "success": True,
                    "file_path": file_path,
                    "local_path": local_file_path,
                    "size": total_size,
                    "message": "æ–‡ä»¶å·²å­˜åœ¨ä¸”å®Œæ•´"
                }
            
            # è®¾ç½®è¯·æ±‚å¤´ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
            headers = {
                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
            }
            
            if resume_pos > 0:
                headers['Range'] = f'bytes={resume_pos}-'
            
            # å¼€å§‹ä¸‹è½½
            response = requests.get(file_url, headers=headers, stream=True, timeout=30)
            
            if response.status_code not in [200, 206]:
                return {
                    "success": False,
                    "error": f"HTTPé”™è¯¯: {response.status_code}",
                    "file_path": file_path,
                    "local_path": local_file_path
                }
            
            # æ‰“å¼€æ–‡ä»¶è¿›è¡Œå†™å…¥
            mode = 'ab' if resume_pos > 0 else 'wb'
            with open(temp_file_path, mode) as f:
                downloaded = resume_pos
                last_progress_time = time.time()
                session_start_time = time.time()  # æœ¬æ¬¡ä¼šè¯å¼€å§‹æ—¶é—´
                session_downloaded = 0  # æœ¬æ¬¡ä¼šè¯ä¸‹è½½çš„å­—èŠ‚æ•°
                
                for chunk in response.iter_content(chunk_size=chunk_size):
                    if chunk:
                        f.write(chunk)
                        downloaded += len(chunk)
                        session_downloaded += len(chunk)
                        
                        # æ˜¾ç¤ºè¿›åº¦ï¼ˆæ¯ç§’æ›´æ–°ä¸€æ¬¡ï¼‰
                        current_time = time.time()
                        if current_time - last_progress_time >= 1.0:
                            progress = (downloaded / total_size) * 100
                            # è®¡ç®—å®é™…ä¸‹è½½é€Ÿåº¦ï¼ˆä»æœ¬æ¬¡ä¼šè¯å¼€å§‹åˆ°ç°åœ¨ï¼‰
                            speed = session_downloaded / (current_time - session_start_time) if (current_time - session_start_time) > 0 else 0
                            print(f"ğŸ“Š è¿›åº¦: {progress:.1f}% ({format_file_size(downloaded)}/{format_file_size(total_size)}) "
                                  f"é€Ÿåº¦: {format_file_size(int(speed))}/s")
                            last_progress_time = current_time
            
            # ä¸‹è½½å®Œæˆï¼Œé‡å‘½åä¸´æ—¶æ–‡ä»¶
            if os.path.exists(local_file_path):
                os.remove(local_file_path)  # åˆ é™¤æ—§æ–‡ä»¶
            os.rename(temp_file_path, local_file_path)
            
            # éªŒè¯æ–‡ä»¶å¤§å°
            final_size = os.path.getsize(local_file_path)
            if final_size == total_size:
                print(f"âœ… ä¸‹è½½å®Œæˆ: {local_file_path}")
                print(f"   å¤§å°: {format_file_size(final_size)}")
                return {
                    "success": True,
                    "file_path": file_path,
                    "local_path": local_file_path,
                    "size": final_size,
                    "message": "ä¸‹è½½æˆåŠŸ"
                }
            else:
                print(f"âš ï¸ æ–‡ä»¶å¤§å°ä¸åŒ¹é…: æœŸæœ› {format_file_size(total_size)}, å®é™… {format_file_size(final_size)}")
                return {
                    "success": False,
                    "error": f"æ–‡ä»¶å¤§å°ä¸åŒ¹é…: æœŸæœ› {total_size}, å®é™… {final_size}",
                    "file_path": file_path,
                    "local_path": local_file_path
                }
                
        except (requests.exceptions.Timeout, requests.exceptions.RequestException) as e:
            error_msg = f"ä¸‹è½½å¼‚å¸¸: {e}"
            print(f"âŒ {error_msg}")
            
            if retry_count < max_retries:
                print(f"ğŸ”„ {retry_delay}ç§’åè¿›è¡Œç¬¬{retry_count + 1}æ¬¡é‡è¯•...")
                time.sleep(retry_delay)
                # æ›´æ–°æ–­ç‚¹ä½ç½®ï¼ˆé‡æ–°æ£€æŸ¥ä¸´æ—¶æ–‡ä»¶å¤§å°ï¼‰
                if os.path.exists(temp_file_path):
                    resume_pos = os.path.getsize(temp_file_path)
                    print(f"ğŸ”„ æ–­ç‚¹ç»­ä¼ ä½ç½®: {format_file_size(resume_pos)}")
                continue
            else:
                print(f"âŒ é‡è¯•{max_retries}æ¬¡åä»ç„¶å¤±è´¥")
                return {
                    "success": False,
                    "error": error_msg,
                    "file_path": file_path,
                    "local_path": local_file_path
                }
        except Exception as e:
            error_msg = f"æœªçŸ¥é”™è¯¯: {e}"
            print(f"âŒ {error_msg}")
            return {
                "success": False,
                "error": error_msg,
                "file_path": file_path,
                "local_path": local_file_path
            }
    
    # é»˜è®¤è¿”å›å€¼ï¼ˆç†è®ºä¸Šä¸ä¼šæ‰§è¡Œåˆ°è¿™é‡Œï¼‰
    return {
        "success": False,
        "error": "æœªçŸ¥é”™è¯¯",
        "file_path": file_path,
        "local_path": local_file_path
    }

def format_file_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
    if size_bytes == 0:
        return "0 B"
    elif size_bytes < 1024:
        return f"{size_bytes} B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f} KB"
    elif size_bytes < 1024 * 1024 * 1024:
        return f"{size_bytes / (1024 * 1024):.1f} MB"
    else:
        return f"{size_bytes / (1024 * 1024 * 1024):.1f} GB"

def check_multiple_files(s3_bucket_url: str, file_list: List[str], local_dir: Optional[str] = None, delay: float = 0.1) -> List[Dict[str, Any]]:
    """
    æ£€æŸ¥å¤šä¸ªæ–‡ä»¶çš„å¤§å°å’Œå¯è®¿é—®æ€§ï¼Œå¯é€‰æ¯”è¾ƒæœ¬åœ°æ–‡ä»¶å¤§å°
    
    Args:
        s3_bucket_url: S3å­˜å‚¨æ¡¶çš„åŸºç¡€URL
        file_list: æ–‡ä»¶è·¯å¾„åˆ—è¡¨
        local_dir: æœ¬åœ°ç›®å½•è·¯å¾„ï¼Œç”¨äºæ¯”è¾ƒæ–‡ä»¶å¤§å°
        delay: è¯·æ±‚ä¹‹é—´çš„å»¶è¿Ÿï¼ˆç§’ï¼‰
        
    Returns:
        æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨
    """
    
    print(f"ğŸš€ å¼€å§‹æ£€æŸ¥ {len(file_list)} ä¸ªæ–‡ä»¶...")
    if local_dir:
        print(f"ğŸ“ å°†æ¯”è¾ƒæœ¬åœ°ç›®å½•: {local_dir}")
    print("=" * 80)
    
    results = []
    accessible_count = 0
    total_size = 0
    mismatch_count = 0
    
    for i, file_path in enumerate(file_list, 1):
        print(f"\n[{i}/{len(file_list)}] ", end="")
        result = check_file_size(s3_bucket_url, file_path)
        
        # å¦‚æœæŒ‡å®šäº†æœ¬åœ°ç›®å½•ï¼Œæ£€æŸ¥æœ¬åœ°æ–‡ä»¶å¤§å°
        if local_dir and result["accessible"]:
            # ä¿æŒå®Œæ•´çš„ç›®å½•ç»“æ„
            local_file_path = os.path.join(local_dir, file_path)
            
            if os.path.exists(local_file_path):
                local_size = os.path.getsize(local_file_path)
                result["local_size"] = local_size
                result["local_size_formatted"] = format_file_size(local_size)
                
                if local_size != result["size_bytes"]:
                    result["size_mismatch"] = True
                    mismatch_count += 1
                    print(f"âš ï¸ å¤§å°ä¸åŒ¹é…: ç½‘ç»œ {format_file_size(result['size_bytes'])}, æœ¬åœ° {format_file_size(local_size)}")
                else:
                    result["size_mismatch"] = False
                    print(f"âœ… å¤§å°åŒ¹é…: {format_file_size(local_size)}")
            else:
                result["local_size"] = 0
                result["local_size_formatted"] = "æ–‡ä»¶ä¸å­˜åœ¨"
                result["size_mismatch"] = False
                print(f"ğŸ“ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨")
        
        results.append(result)
        
        if result["accessible"]:
            accessible_count += 1
            total_size += result["size_bytes"]
        
        # æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
        if i < len(file_list):
            time.sleep(delay)
    
    # æ‰“å°æ±‡æ€»ä¿¡æ¯
    print(f"\n{'='*20} æ£€æŸ¥ç»“æœæ±‡æ€» {'='*20}")
    print(f"æ€»æ–‡ä»¶æ•°: {len(file_list)}")
    print(f"å¯è®¿é—®æ–‡ä»¶: {accessible_count}")
    print(f"ä¸å¯è®¿é—®æ–‡ä»¶: {len(file_list) - accessible_count}")
    print(f"æˆåŠŸç‡: {accessible_count/len(file_list)*100:.1f}%")
    print(f"æ€»å¤§å°: {format_file_size(total_size)}")
    
    if local_dir:
        print(f"æœ¬åœ°ç›®å½•: {local_dir}")
        print(f"å¤§å°ä¸åŒ¹é…æ–‡ä»¶: {mismatch_count}")
        if mismatch_count > 0:
            print("âš ï¸ å‘ç°å¤§å°ä¸åŒ¹é…çš„æ–‡ä»¶ï¼Œå»ºè®®é‡æ–°ä¸‹è½½")
    
    return results

def get_expected_files_from_env_desc() -> List[str]:
    """ä»env_desc.pyè·å–æœŸæœ›çš„æ–‡ä»¶åˆ—è¡¨"""
    try:
        # å°è¯•å¯¼å…¥data_lake_dict
        import sys
        import os
        
        # æ·»åŠ é¡¹ç›®è·¯å¾„
        project_root = os.path.dirname(os.path.abspath(__file__))
        if project_root.endswith('scripts'):
            project_root = os.path.dirname(project_root)
        sys.path.insert(0, project_root)
        
        from biomni.env_desc import data_lake_dict
        
        # è·å–data_lakeæ–‡ä»¶åˆ—è¡¨
        data_lake_files = [f"data_lake/{filename}" for filename in data_lake_dict.keys()]
        
        # æ·»åŠ benchmarkæ–‡ä»¶
        benchmark_files = [
            "benchmark.zip"  # benchmarkæ–‡ä»¶å¤¹é€šå¸¸ä½œä¸ºzipæ–‡ä»¶ä¸‹è½½
        ]
        
        return data_lake_files + benchmark_files
        
    except ImportError as e:
        print(f"âš ï¸ æ— æ³•å¯¼å…¥biomniæ¨¡å—: {e}")
        print("å°†ä½¿ç”¨é»˜è®¤æ–‡ä»¶åˆ—è¡¨")
        return []

def show_usage():
    """æ˜¾ç¤ºä½¿ç”¨è¯´æ˜"""
    print("""
ğŸ§¬ Biomni S3æ–‡ä»¶å·¥å…· - ä½¿ç”¨è¯´æ˜

ç”¨æ³•:
  python check_s3_file.py [å‘½ä»¤] [å‚æ•°]

å‘½ä»¤:
  check <æ–‡ä»¶è·¯å¾„>           - æ£€æŸ¥æŒ‡å®šæ–‡ä»¶çš„å¤§å°å’Œå¯è®¿é—®æ€§
  download <æ–‡ä»¶è·¯å¾„> [ç›®å½•]  - ä¸‹è½½æŒ‡å®šæ–‡ä»¶åˆ°æœ¬åœ°ç›®å½•ï¼ˆé»˜è®¤å½“å‰ç›®å½•ï¼‰
  list [æœ¬åœ°ç›®å½•]            - æ£€æŸ¥æ‰€æœ‰æœŸæœ›çš„æ–‡ä»¶ï¼Œå¯é€‰æ¯”è¾ƒæœ¬åœ°æ–‡ä»¶å¤§å°
  help                      - æ˜¾ç¤ºæ­¤å¸®åŠ©ä¿¡æ¯

ç¤ºä¾‹:
  python check_s3_file.py check data_lake/gene_info.parquet
  python check_s3_file.py download data_lake/gene_info.parquet
  python check_s3_file.py download data_lake/gene_info.parquet ./downloads
  python check_s3_file.py list
  python check_s3_file.py list ./data/biomni_data

ç‰¹æ€§:
  âœ… æ”¯æŒæ–­ç‚¹ç»­ä¼ 
  âœ… è‡ªåŠ¨é‡è¯•ï¼ˆç½‘ç»œå¼‚å¸¸æ—¶ï¼‰
  âœ… æ˜¾ç¤ºä¸‹è½½è¿›åº¦å’Œé€Ÿåº¦
  âœ… è‡ªåŠ¨éªŒè¯æ–‡ä»¶å®Œæ•´æ€§
  âœ… æ”¯æŒæ‰¹é‡æ£€æŸ¥
  âœ… æ¯”è¾ƒç½‘ç»œå’Œæœ¬åœ°æ–‡ä»¶å¤§å°
""")

def main():
    """ä¸»å‡½æ•°"""
    s3_bucket_url = "https://biomni-release.s3.amazonaws.com"
    
    print("ğŸ§¬ Biomni S3æ–‡ä»¶å·¥å…·")
    print("=" * 80)
    print(f"ç›®æ ‡å­˜å‚¨æ¡¶: {s3_bucket_url}")
    print("=" * 80)
    
    # æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) < 2:
        show_usage()
        return
    
    command = sys.argv[1].lower()
    
    if command == "help":
        show_usage()
        return
    
    elif command == "check":
        if len(sys.argv) < 3:
            print("âŒ è¯·æŒ‡å®šè¦æ£€æŸ¥çš„æ–‡ä»¶è·¯å¾„")
            print("ç”¨æ³•: python check_s3_file.py check <æ–‡ä»¶è·¯å¾„>")
            return
        
        file_path = sys.argv[2]
        print(f"æ£€æŸ¥æŒ‡å®šæ–‡ä»¶: {file_path}")
        result = check_file_size(s3_bucket_url, file_path)
        
        if result["accessible"]:
            print(f"\nâœ… æ–‡ä»¶ä¿¡æ¯:")
            print(f"   è·¯å¾„: {result['file_path']}")
            print(f"   å¤§å°: {format_file_size(result['size_bytes'])}")
            print(f"   ç±»å‹: {result['content_type']}")
            if result['last_modified']:
                print(f"   ä¿®æ”¹æ—¶é—´: {result['last_modified']}")
        else:
            print(f"\nâŒ æ–‡ä»¶ä¸å¯è®¿é—®: {result['error']}")
    
    elif command == "download":
        if len(sys.argv) < 3:
            print("âŒ è¯·æŒ‡å®šè¦ä¸‹è½½çš„æ–‡ä»¶è·¯å¾„")
            print("ç”¨æ³•: python check_s3_file.py download <æ–‡ä»¶è·¯å¾„> [ç›®å½•]")
            return
        
        file_path = sys.argv[2]
        local_dir = sys.argv[3] if len(sys.argv) > 3 else "."
        
        print(f"ä¸‹è½½æ–‡ä»¶: {file_path} åˆ°ç›®å½•: {local_dir}")
        result = download_file_with_resume(s3_bucket_url, file_path, local_dir)
        
        if result["success"]:
            print(f"\nâœ… ä¸‹è½½æˆåŠŸ: {result['local_path']}")
            print(f"   å¤§å°: {format_file_size(result['size'])}")
        else:
            print(f"\nâŒ ä¸‹è½½å¤±è´¥: {result['error']}")
    
    elif command == "list":
        # æ£€æŸ¥æ‰€æœ‰æœŸæœ›çš„æ–‡ä»¶
        print("è·å–æœŸæœ›çš„æ–‡ä»¶åˆ—è¡¨...")
        expected_files = get_expected_files_from_env_desc()
        
        if not expected_files:
            # ä½¿ç”¨ä¸€äº›å¸¸è§çš„æ–‡ä»¶ä½œä¸ºç¤ºä¾‹
            expected_files = [
                "data_lake/gene_info.parquet",
                "data_lake/hp.obo",
                "data_lake/txgnn_name_mapping.pkl",
                "data_lake/txgnn_prediction.pkl",
                "data_lake/sgRNA/KO_SP_human.txt",
                "data_lake/sgRNA/KO_SP_mouse.txt",
                "benchmark.zip"
            ]
            print("ä½¿ç”¨ç¤ºä¾‹æ–‡ä»¶åˆ—è¡¨")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æœ¬åœ°ç›®å½•å‚æ•°
        local_dir = None
        if len(sys.argv) > 2:
            local_dir = sys.argv[2]
            print(f"å°†æ¯”è¾ƒæœ¬åœ°ç›®å½•: {local_dir}")
        
        print(f"å°†æ£€æŸ¥ {len(expected_files)} ä¸ªæ–‡ä»¶")
        
        # è¯¢é—®ç”¨æˆ·æ˜¯å¦ç»§ç»­
        response = input("\næ˜¯å¦ç»§ç»­æ£€æŸ¥æ‰€æœ‰æ–‡ä»¶? (y/n): ").lower().strip()
        if response in ['y', 'yes', 'æ˜¯']:
            results = check_multiple_files(s3_bucket_url, expected_files, local_dir)
            
            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            output_file = "s3_file_check_results.txt"
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write("S3æ–‡ä»¶æ£€æŸ¥ç»“æœ\n")
                f.write("=" * 50 + "\n")
                f.write(f"æ£€æŸ¥æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"å­˜å‚¨æ¡¶: {s3_bucket_url}\n")
                if local_dir:
                    f.write(f"æœ¬åœ°ç›®å½•: {local_dir}\n")
                f.write("\n")
                
                for result in results:
                    f.write(f"æ–‡ä»¶: {result['file_path']}\n")
                    f.write(f"çŠ¶æ€: {'å¯è®¿é—®' if result['accessible'] else 'ä¸å¯è®¿é—®'}\n")
                    if result['accessible']:
                        f.write(f"å¤§å°: {format_file_size(result['size_bytes'])}\n")
                        f.write(f"ç±»å‹: {result['content_type']}\n")
                        if local_dir and 'local_size' in result:
                            f.write(f"æœ¬åœ°å¤§å°: {result['local_size_formatted']}\n")
                            if result.get('size_mismatch', False):
                                f.write("âš ï¸ å¤§å°ä¸åŒ¹é…\n")
                    else:
                        f.write(f"é”™è¯¯: {result['error']}\n")
                    f.write("-" * 30 + "\n")
            
            print(f"\nç»“æœå·²ä¿å­˜åˆ°: {output_file}")
        else:
            print("æ£€æŸ¥å·²å–æ¶ˆ")
    
    else:
        print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
        show_usage()

if __name__ == "__main__":
    main() 