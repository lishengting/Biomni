import gradio as gr
import os
import threading
import time
import re
import json
from typing import Optional

# Session management for multiple users
import uuid
from datetime import datetime
from typing import Dict, Optional

class SessionManager:
    def __init__(self):
        self.sessions: Dict[str, Dict] = {}
        self.lock = threading.Lock()
    
    def create_session(self, session_id: str) -> Dict:
        """åˆ›å»ºæ–°çš„ç”¨æˆ·ä¼šè¯"""
        with self.lock:
            session = {
                'id': session_id,
                'agent': None,
                'agent_error': None,
                'current_task': None,
                'stop_flag': False,
                'created_at': datetime.now(),
                'last_activity': datetime.now()
            }
            self.sessions[session_id] = session
            return session
    
    def get_session(self, session_id: str) -> Optional[Dict]:
        """è·å–ç”¨æˆ·ä¼šè¯"""
        with self.lock:
            return self.sessions.get(session_id)
    
    def update_session(self, session_id: str, **kwargs):
        """æ›´æ–°ä¼šè¯ä¿¡æ¯"""
        with self.lock:
            if session_id in self.sessions:
                self.sessions[session_id].update(kwargs)
                self.sessions[session_id]['last_activity'] = datetime.now()
    
    def remove_session(self, session_id: str):
        """ç§»é™¤ç”¨æˆ·ä¼šè¯"""
        with self.lock:
            if session_id in self.sessions:
                # æ¸…ç†agentèµ„æº
                session = self.sessions[session_id]
                if session['agent']:
                    try:
                        session['agent'].stop()
                    except:
                        pass
                del self.sessions[session_id]

# å…¨å±€ä¼šè¯ç®¡ç†å™¨
session_manager = SessionManager()

# å…¼å®¹æ€§å˜é‡ï¼ˆç”¨äºå‘åå…¼å®¹ï¼‰
agent = None
agent_error = None
current_task = None
stop_flag = False

def parse_advanced_content(content: str) -> str:
    """
    é«˜çº§å†…å®¹è§£æå‡½æ•°ï¼Œå°†ä¸åŒæ ¼å¼çš„å†…å®¹è½¬æ¢ä¸ºHTMLæ˜¾ç¤º
    - æ™®é€šå†…å®¹æŒ‰markdownæ ¼å¼è§£æ
    - <execute></execute>ä¸­çš„å†…å®¹ç”¨æ·±è‰²ä»£ç çª—æ˜¾ç¤º
    - <observation></observation>å’Œ<solution></solution>ä¸­çš„å†…å®¹ï¼Œå¦‚æœæ˜¯JSONå°±ç”¨JSONç¾åŒ–æ˜¾ç¤ºï¼Œå¦åˆ™æŒ‰markdownæ ¼å¼è§£æ
    """
    if not content:
        return ""
    
    # å®šä¹‰ä¸åŒæ ‡ç­¾çš„å¤„ç†å‡½æ•°
    def process_execute_tag(match):
        """å¤„ç†<execute>æ ‡ç­¾ï¼Œç”¨æ·±è‰²ä»£ç çª—æ˜¾ç¤º"""
        inner_content = match.group(1)
        # è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦
        inner_content = inner_content.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
        return f'<div class="execute-block"><strong>ğŸ”§ Execute:</strong><br><pre>{inner_content}</pre></div>'
    
    def process_observation_tag(match):
        """å¤„ç†<observation>æ ‡ç­¾ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºJSONæ ¼å¼"""
        inner_content = match.group(1).strip()
        try:
            # å°è¯•è§£æä¸ºJSON
            json_data = json.loads(inner_content)
            # ç¾åŒ–JSONæ˜¾ç¤º
            formatted_json = json.dumps(json_data, indent=2, ensure_ascii=False)
            return f'<div class="observation-block"><strong>ğŸ‘ï¸ Observation:</strong><br><pre>{formatted_json}</pre></div>'
        except (json.JSONDecodeError, ValueError):
            # ä¸æ˜¯JSONï¼ŒæŒ‰markdownæ ¼å¼å¤„ç†
            # ç®€å•çš„markdownè½¬HTMLå¤„ç†
            processed_content = inner_content.replace('**', '<strong>').replace('**', '</strong>')
            processed_content = processed_content.replace('`', '<code>').replace('`', '</code>')
            return f'<div class="observation-block"><strong>ğŸ‘ï¸ Observation:</strong><br>{processed_content}</div>'
    
    def process_solution_tag(match):
        """å¤„ç†<solution>æ ‡ç­¾ï¼Œåˆ¤æ–­æ˜¯å¦ä¸ºJSONæ ¼å¼"""
        inner_content = match.group(1).strip()
        try:
            # å°è¯•è§£æä¸ºJSON
            json_data = json.loads(inner_content)
            # ç¾åŒ–JSONæ˜¾ç¤º
            formatted_json = json.dumps(json_data, indent=2, ensure_ascii=False)
            return f'<div class="solution-block"><strong>ğŸ’¡ Solution:</strong><br><pre>{formatted_json}</pre></div>'
        except (json.JSONDecodeError, ValueError):
            # ä¸æ˜¯JSONï¼ŒæŒ‰markdownæ ¼å¼å¤„ç†
            # ç®€å•çš„markdownè½¬HTMLå¤„ç†
            processed_content = inner_content.replace('**', '<strong>').replace('**', '</strong>')
            processed_content = processed_content.replace('`', '<code>').replace('`', '</code>')
            return f'<div class="solution-block"><strong>ğŸ’¡ Solution:</strong><br>{processed_content}</div>'
    
    def process_think_tag(match):
        """å¤„ç†<think>æ ‡ç­¾ï¼Œç”¨ç°è‰²å°å·å­—ä½“æ˜¾ç¤º"""
        inner_content = match.group(1).strip()
        # è½¬ä¹‰HTMLç‰¹æ®Šå­—ç¬¦
        inner_content = inner_content.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
        return f'<div class="think-block"><strong>ğŸ’­ Thinking:</strong><br><span class="think-content">{inner_content}</span></div>'
    
    # å…ˆå¤„ç†ç‰¹æ®Šæ ‡ç­¾
    content = re.sub(r'<execute>(.*?)</execute>', process_execute_tag, content, flags=re.DOTALL)
    content = re.sub(r'<observation>(.*?)</observation>', process_observation_tag, content, flags=re.DOTALL)
    content = re.sub(r'<solution>(.*?)</solution>', process_solution_tag, content, flags=re.DOTALL)
    content = re.sub(r'<think>(.*?)</think>', process_think_tag, content, flags=re.DOTALL)
    
    # å¤„ç†å…¶ä»–markdownæ ¼å¼
    # å¤„ç†æ ‡é¢˜
    content = re.sub(r'^### (.*?)$', r'<h3>\1</h3>', content, flags=re.MULTILINE)
    content = re.sub(r'^## (.*?)$', r'<h2>\1</h2>', content, flags=re.MULTILINE)
    content = re.sub(r'^\*\* (.*?) \*\*$', r'<h4>\1</h4>', content, flags=re.MULTILINE)
    
    # å¤„ç†ç²—ä½“
    content = re.sub(r'\*\*(.*?)\*\*', r'<strong>\1</strong>', content)
    
    # å¤„ç†ä»£ç å—
    content = re.sub(r'```(.*?)```', r'<pre>\1</pre>', content, flags=re.DOTALL)
    
    # å¤„ç†è¡Œå†…ä»£ç 
    content = re.sub(r'`(.*?)`', r'<code>\1</code>', content)
    
    # å¤„ç†åˆ—è¡¨
    content = re.sub(r'^- (.*?)$', r'<li>\1</li>', content, flags=re.MULTILINE)
    content = re.sub(r'(\n<li.*?</li>\n)+', r'<ul>\g<0></ul>', content)
    
    # å¤„ç†æ¢è¡Œ
    content = content.replace('\n', '<br>')
    
    return f'<div class="content-wrapper">{content}</div>'

def create_agent(llm_model: str, source: str, base_url: Optional[str], api_key: Optional[str], data_path: str, verbose: bool, session_id: str = ""):
    """Create a new Biomni agent with the specified configuration."""
    global agent, agent_error
    
    print(f"[LOG] åˆ›å»ºagentï¼Œsession_id: {session_id}")  # æ·»åŠ æ—¥å¿—
    
    # ç”Ÿæˆä¼šè¯IDï¼ˆå¦‚æœæœªæä¾›ï¼‰
    if not session_id or session_id == "":
        session_id = str(uuid.uuid4())
        print(f"[LOG] ç”Ÿæˆæ–°session_id: {session_id}")  # æ·»åŠ æ—¥å¿—
    
    # åˆ›å»ºæˆ–è·å–ä¼šè¯
    session = session_manager.get_session(session_id)
    if not session:
        session = session_manager.create_session(session_id)
        print(f"[LOG] åˆ›å»ºæ–°ä¼šè¯: {session_id}")  # æ·»åŠ æ—¥å¿—
    else:
        print(f"[LOG] ä½¿ç”¨ç°æœ‰ä¼šè¯: {session_id}")  # æ·»åŠ æ—¥å¿—
    
    # æ‰“å°å½“å‰æ‰€æœ‰ä¼šè¯ä¿¡æ¯
    print(f"[LOG] å½“å‰æ´»è·ƒä¼šè¯æ•°é‡: {len(session_manager.sessions)}")
    for sid, sess in session_manager.sessions.items():
        print(f"[LOG] ä¼šè¯ {sid}: agent={sess['agent'] is not None}, error={sess['agent_error']}")
    
    # æ‰“å°å…¨å±€agentçŠ¶æ€
    print(f"[LOG] å…¨å±€agentçŠ¶æ€: agent={agent is not None}, error={agent_error}")
    
    try:
        from biomni.agent import A1
        
        # Prepare agent parameters
        agent_params = {
            "path": data_path,
            "llm": llm_model,
            "verbose": verbose,
        }
        
        # Add source if specified
        if source and source != "Auto-detect":
            agent_params["source"] = source
            
        # Add base_url and api_key if provided
        if base_url and base_url.strip():
            agent_params["base_url"] = base_url.strip()
            
        if api_key and api_key.strip():
            agent_params["api_key"] = api_key.strip()
            
        # Create the agent
        session_agent = A1(**agent_params)
        session_manager.update_session(session_id, agent=session_agent, agent_error=None)
        
        # ä¸å†æ›´æ–°å…¨å±€å˜é‡ï¼Œä¿æŒä¼šè¯ç‹¬ç«‹æ€§
        # agent = session_agent  # æ³¨é‡Šæ‰ï¼Œé¿å…å…±äº«
        # agent_error = None     # æ³¨é‡Šæ‰ï¼Œé¿å…å…±äº«
        
        verbose_status = "enabled" if verbose else "disabled"
        return "âœ… Agent created successfully!", f"Current configuration:\n- Model: {llm_model}\n- Source: {source}\n- Base URL: {base_url or 'Default'}\n- Data Path: {data_path}\n- Verbose logging: {verbose_status}\n- Session ID: {session_id}"
        
    except Exception as e:
        session_manager.update_session(session_id, agent=None, agent_error=str(e))
        # ä¸å†æ›´æ–°å…¨å±€å˜é‡ï¼Œä¿æŒä¼šè¯ç‹¬ç«‹æ€§
        # agent = None  # æ³¨é‡Šæ‰ï¼Œé¿å…å…±äº«
        # agent_error = str(e)  # æ³¨é‡Šæ‰ï¼Œé¿å…å…±äº«
        return f"âŒ Failed to create agent: {str(e)}", ""

def stop_execution(session_id: str = ""):
    """Stop the current execution."""
    global stop_flag, agent
    
    # å¦‚æœæ²¡æœ‰æä¾›session_idï¼Œåœæ­¢æ‰€æœ‰ä¼šè¯
    if not session_id or session_id == "":
        stop_flag = True
        if agent:
            agent.stop()
        return "â¹ï¸ Stopping execution...", "Execution stopped."
    
    # åœæ­¢ç‰¹å®šä¼šè¯
    session = session_manager.get_session(session_id)
    if session:
        session_manager.update_session(session_id, stop_flag=True)
        if session['agent']:
            session['agent'].stop()
        return "â¹ï¸ Stopping execution...", "Execution stopped."
    
    return "â¹ï¸ No active session found.", "No session to stop."

def ask_biomni_stream(question: str, session_id: str = ""):
    """Ask a question to the Biomni agent with streaming output."""
    global agent, agent_error, current_task, stop_flag
    
    print(f"[LOG] æé—®ï¼Œsession_id: {session_id}, question: {question[:50]}...")  # æ·»åŠ æ—¥å¿—
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„ä¼šè¯ID
    if not session_id or session_id == "" or session_id == "No session assigned":
        print(f"[LOG] æ²¡æœ‰æœ‰æ•ˆçš„session_idï¼Œæç¤ºç”¨æˆ·å…ˆåˆ›å»ºagent")  # æ·»åŠ æ—¥å¿—
        yield f"âŒ No session assigned. Please click 'ğŸš€ Create Agent' button first to create a session.", ""
        return
    
    print(f"[LOG] ä½¿ç”¨ä¼ å…¥çš„session_id: {session_id}")  # æ·»åŠ æ—¥å¿—
    
    # æ¸…ç†æ—§ä¼šè¯
    cleanup_old_sessions()
    
    # æ‰“å°ä¼šè¯çŠ¶æ€æŠ¥å‘Š
    print_session_status()
    
    # è·å–ä¼šè¯
    session = session_manager.get_session(session_id)
    if not session:
        # å¦‚æœæ²¡æœ‰ä¼šè¯ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤ä¼šè¯
        session = session_manager.create_session(session_id)
        print(f"[LOG] åˆ›å»ºæ–°ä¼šè¯: {session_id}")  # æ·»åŠ æ—¥å¿—
    else:
        print(f"[LOG] ä½¿ç”¨ç°æœ‰ä¼šè¯: {session_id}")  # æ·»åŠ æ—¥å¿—
    
    session_agent = session['agent']
    session_error = session['agent_error']
    
    print(f"[LOG] æé—®æ—¶ä¼šè¯çŠ¶æ€: agent={session_agent is not None}, error={session_error}")  # æ·»åŠ æ—¥å¿—
    
    # å¦‚æœå½“å‰ä¼šè¯æ²¡æœ‰agentï¼Œæç¤ºç”¨æˆ·å…ˆåˆ›å»ºagent
    if session_agent is None:
        print(f"[LOG] ä¼šè¯ {session_id} æ²¡æœ‰agentï¼Œæç¤ºç”¨æˆ·å…ˆåˆ›å»º")  # æ·»åŠ æ—¥å¿—
        yield f"âŒ Biomni agent not initialized for session {session_id}.\n\nè¯·å…ˆç‚¹å‡»'ğŸš€ Create Agent'æŒ‰é’®åˆ›å»ºagentï¼Œç„¶åå†æé—®ã€‚\n\næ³¨æ„ï¼šæ¯ä¸ªä¼šè¯éƒ½éœ€è¦ç‹¬ç«‹åˆ›å»ºagentã€‚", ""
        return
    
    if not question.strip():
        yield "âŒ Please enter a question.", ""
        return
    
    session_manager.update_session(session_id, stop_flag=False)
    
    try:
        # Clear previous execution logs
        session_agent.clear_execution_logs()
        
        # Start execution in a separate thread
        result_container = {}
        
        def execute_task():
            try:
                result_container['result'] = session_agent.go(question.strip())
                result_container['completed'] = True
            except Exception as e:
                result_container['error'] = str(e)
                result_container['completed'] = True
        
        # Start the execution thread
        session_task = threading.Thread(target=execute_task)
        session_manager.update_session(session_id, current_task=session_task)
        session_task.start()
        
        # Stream updates while task is running
        last_step_count = 0
        last_intermediate_count = 0
        
        while session_task.is_alive():
            # æ£€æŸ¥åœæ­¢æ ‡å¿—
            session = session_manager.get_session(session_id)
            if session and session['stop_flag']:
                # Call agent's stop method to actually stop execution
                if session_agent:
                    session_agent.stop()
                # Stop showing updates
                yield "â¹ï¸ **Stopping execution...**", "\n".join([entry["formatted"] for entry in session_agent.get_execution_logs()])
                session_task.join(timeout=1)  # Give it a moment to finish
                return
            
            # Get current logs
            logs = session_agent.get_execution_logs()
            execution_log = "\n".join([entry["formatted"] for entry in logs])
            
            # Get intermediate outputs
            intermediate_outputs = session_agent.get_intermediate_outputs()
            current_step = session_agent.get_current_step()
            
            # Check if we have new steps or intermediate results
            if len(logs) > last_step_count or len(intermediate_outputs) > last_intermediate_count:
                last_step_count = len(logs)
                last_intermediate_count = len(intermediate_outputs)
                
                # Format progress message
                latest_logs = logs[-min(3, len(logs)):]  # Show last 3 log entries
                progress = f"ğŸ”„ **Running...** (Step {current_step})\n\n**Recent Activity:**\n" + "\n".join([log["formatted"] for log in latest_logs])
                
                # Format intermediate results with advanced parsing
                intermediate_text = ""
                if intermediate_outputs:
                    intermediate_text = f"<div style='margin: 30px 0; padding: 20px; background: linear-gradient(135deg, #28a745 0%, #20c997 100%); color: white; border-radius: 10px; text-align: center;'><h2 style='margin: 0; font-size: 1.5em;'>âš™ï¸ Execution Steps ({len(intermediate_outputs)} total)</h2></div>\n\n"
                    # Show all intermediate outputs without truncation
                    for output in intermediate_outputs:
                        step_header = f"<div style='margin: 40px 0 20px 0; border-top: 3px solid #007acc; padding-top: 20px;'><h3><strong>ğŸ“ Step {output['step']} ({output['message_type']}) - {output['timestamp']}</strong></h3></div>"
                        step_content = output['content']
                        # ä½¿ç”¨é«˜çº§è§£æå‡½æ•°å¤„ç†å†…å®¹
                        parsed_content = parse_advanced_content(step_content)
                        intermediate_text += f"{step_header}\n{parsed_content}\n\n"
                else:
                    intermediate_text = "â³ Processing... Please wait for intermediate results."
                
                yield intermediate_text, execution_log
            
            time.sleep(0.5)  # Update every 0.5 seconds for better responsiveness
        
        # Wait for task to complete
        session_task.join()
        
        # Handle results
        if 'error' in result_container:
            execution_log = "\n".join([entry["formatted"] for entry in session_agent.get_execution_logs()])
            yield f"âŒ **Error:** {result_container['error']}", execution_log
            return
        
        if 'result' in result_container:
            result = result_container['result']
            
            # Format the full execution log
            execution_log = "\n".join([entry["formatted"] for entry in session_agent.get_execution_logs()])
            
            # Format the final output with advanced parsing
            intermediate_text = ""
            
            # Add intermediate outputs with advanced parsing
            intermediate_outputs = session_agent.get_intermediate_outputs()
            if intermediate_outputs:
                intermediate_text += f"<div style='margin: 30px 0; padding: 20px; background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; border-radius: 10px; text-align: center;'><h2 style='margin: 0; font-size: 1.5em;'>ğŸ“Š Detailed Steps ({len(intermediate_outputs)} total)</h2></div>\n\n"
                for output in intermediate_outputs:
                    step_header = f"<div style='margin: 40px 0 20px 0; border-top: 3px solid #007acc; padding-top: 20px;'><h3><strong>ğŸ“ Step {output['step']} ({output['message_type']}) - {output['timestamp']}</strong></h3></div>"
                    step_content = output['content']
                    # ä½¿ç”¨é«˜çº§è§£æå‡½æ•°å¤„ç†å†…å®¹
                    parsed_content = parse_advanced_content(step_content)
                    intermediate_text += f"{step_header}\n{parsed_content}\n\n"
            
            if not intermediate_outputs:
                intermediate_text += "No intermediate results available."
            
            yield intermediate_text, execution_log
        else:
            yield "âŒ No result received.", "\n".join([entry["formatted"] for entry in session_agent.get_execution_logs()])
            
    except Exception as e:
        execution_log = "\n".join([entry["formatted"] for entry in session_agent.get_execution_logs()]) if session_agent else ""
        yield f"âŒ Error processing question: {str(e)}", execution_log

def ask_biomni(question: str):
    """Non-streaming version for backward compatibility."""
    for result in ask_biomni_stream(question):
        final_result = result
    return final_result

def reset_agent(session_id: str = ""):
    """Reset the agent."""
    global agent, agent_error
    
    # å¦‚æœæ²¡æœ‰æä¾›session_idï¼Œé‡ç½®å…¨å±€agent
    if not session_id or session_id == "":
        agent = None
        agent_error = None
        return "Agent reset. Please configure and create a new agent.", ""
    
    # é‡ç½®ç‰¹å®šä¼šè¯
    session_manager.remove_session(session_id)
    return "Agent reset. Please configure and create a new agent.", ""

# ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯ID
def generate_session_id():
    """ç”Ÿæˆå”¯ä¸€çš„ä¼šè¯ID"""
    return str(uuid.uuid4())

# è·å–å½“å‰æ—¶é—´æˆ³ä½œä¸ºä¼šè¯IDçš„ä¸€éƒ¨åˆ†
def get_timestamp_session_id():
    """ä½¿ç”¨æ—¶é—´æˆ³ç”Ÿæˆä¼šè¯IDï¼Œç¡®ä¿æ¯ä¸ªé¡µé¢åŠ è½½éƒ½æœ‰ä¸åŒçš„ID"""
    import time
    return f"session_{int(time.time() * 1000)}_{uuid.uuid4().hex[:8]}"

def refresh_session_id():
    """åˆ·æ–°ä¼šè¯IDï¼Œç¡®ä¿æ¯æ¬¡è°ƒç”¨éƒ½ç”Ÿæˆæ–°çš„ID"""
    return get_timestamp_session_id()

def cleanup_old_sessions():
    """æ¸…ç†æ—§çš„ä¼šè¯ï¼Œåªä¿ç•™æœ€è¿‘çš„å‡ ä¸ª"""
    print(f"[LOG] æ¸…ç†å‰ä¼šè¯æ•°é‡: {len(session_manager.sessions)}")  # æ·»åŠ æ—¥å¿—
    if len(session_manager.sessions) > 10:  # å¦‚æœä¼šè¯æ•°é‡è¶…è¿‡10ä¸ªï¼Œæ¸…ç†æ—§çš„
        # æŒ‰æœ€åæ´»åŠ¨æ—¶é—´æ’åºï¼Œä¿ç•™æœ€æ–°çš„5ä¸ª
        sorted_sessions = sorted(session_manager.sessions.items(), 
                               key=lambda x: x[1]['last_activity'], 
                               reverse=True)
        sessions_to_keep = sorted_sessions[:5]
        sessions_to_remove = sorted_sessions[5:]
        
        for session_id, _ in sessions_to_remove:
            session_manager.remove_session(session_id)
            print(f"[LOG] æ¸…ç†æ—§ä¼šè¯: {session_id}")  # æ·»åŠ æ—¥å¿—
        
        print(f"[LOG] æ¸…ç†åä¼šè¯æ•°é‡: {len(session_manager.sessions)}")  # æ·»åŠ æ—¥å¿—

def print_session_status():
    """æ‰“å°æ‰€æœ‰ä¼šè¯çŠ¶æ€ï¼Œç”¨äºè°ƒè¯•"""
    print(f"[LOG] === ä¼šè¯çŠ¶æ€æŠ¥å‘Š ===")
    print(f"[LOG] å…¨å±€agent: {agent is not None}")
    print(f"[LOG] æ´»è·ƒä¼šè¯æ•°é‡: {len(session_manager.sessions)}")
    for sid, sess in session_manager.sessions.items():
        print(f"[LOG] ä¼šè¯ {sid}: agent={sess['agent'] is not None}, error={sess['agent_error']}")
    print(f"[LOG] ===================")

# Create the Gradio interface
with gr.Blocks(title="Biomni AI Agent Demo", theme=gr.themes.Soft(), css="""
    .intermediate-results {
        max-height: 800px;
        overflow-y: auto;
        padding: 20px;
        background-color: #ffffff;
        border-radius: 8px;
        border: 1px solid #e1e5e9;
    }
    
    .intermediate-results::-webkit-scrollbar {
        width: 8px;
    }
    
    .intermediate-results::-webkit-scrollbar-track {
        background: #f1f1f1;
        border-radius: 4px;
    }
    
    .intermediate-results::-webkit-scrollbar-thumb {
        background: #c1c1c1;
        border-radius: 4px;
    }
    
    .intermediate-results::-webkit-scrollbar-thumb:hover {
        background: #a8a8a8;
    }
    
    /* è‡ªå®šä¹‰ä»£ç å—æ ·å¼ */
    .intermediate-results pre {
        background-color: #f8f9fa;
        border: 1px solid #e9ecef;
        border-radius: 6px;
        padding: 12px;
        margin: 10px 0;
        overflow-x: auto;
        font-family: 'Courier New', monospace;
        font-size: 14px;
        line-height: 1.4;
    }
    
    /* è‡ªå®šä¹‰æ ‡ç­¾æ ·å¼ */
    .intermediate-results .execute-block {
        background-color: #1e1e1e;
        color: #d4d4d4;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
        font-family: 'Courier New', monospace;
        white-space: pre-wrap;
        border-left: 4px solid #007acc;
    }
    
    .intermediate-results .observation-block {
        background-color: #f8f9fa;
        border: 1px solid #e9ecef;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
    }
    
    .intermediate-results .solution-block {
        background-color: #e8f5e8;
        border: 1px solid #c3e6c3;
        padding: 15px;
        border-radius: 8px;
        margin: 10px 0;
    }
    
    .intermediate-results .think-block {
        background-color: #f8f9fa;
        border: 1px solid #e9ecef;
        padding: 10px;
        border-radius: 6px;
        margin: 8px 0;
    }
    
    .intermediate-results .think-content {
        color: #6c757d;
        font-size: 0.9em;
        font-style: italic;
        line-height: 1.4;
    }
    
    /* å†…å®¹åŒ…è£…å™¨æ ·å¼ */
    .intermediate-results .content-wrapper {
        font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
        line-height: 1.6;
        color: #333;
    }
    
    .intermediate-results h2 {
        color: #34495e;
        margin: 25px 0 15px 0;
        border-bottom: 2px solid #ecf0f1;
        padding-bottom: 5px;
    }
    
    .intermediate-results h3 {
        color: #2c3e50;
        margin: 20px 0 10px 0;
    }
    
    .intermediate-results h4 {
        color: #7f8c8d;
        margin: 15px 0 8px 0;
    }
    
    .intermediate-results code {
        background-color: #f4f4f4;
        padding: 2px 4px;
        border-radius: 3px;
        font-family: monospace;
    }
    
    .intermediate-results li {
        margin: 5px 0;
    }
    
    .intermediate-results ul {
        margin: 10px 0;
        padding-left: 20px;
    }
""") as demo:
    gr.Markdown("# ğŸ§¬ Biomni AI Agent Demo")
    gr.Markdown("Configure your LLM settings and ask Biomni to run biomedical tasks!")
    
    # æ˜¾ç¤ºå½“å‰ä¼šè¯IDï¼ˆç”¨äºè°ƒè¯•ï¼‰
    session_display = gr.Textbox(
        label="Session ID (Debug)",
        value="No session assigned",
        interactive=False,
        visible=True  # ä¸´æ—¶è®¾ä¸ºå¯è§ï¼Œç”¨äºè°ƒè¯•
    )
    
    # æ˜¾ç¤ºä¼šè¯çŠ¶æ€
    session_status = gr.Textbox(
        label="Session Status",
        value="No agent created",
        interactive=False,
        visible=True
    )
    
    # éšè—çš„ä¼šè¯IDç»„ä»¶ - åˆå§‹ä¸ºç©º
    session_id_state = gr.State(value="")
    
    with gr.Row():
        with gr.Column(scale=1):
            gr.Markdown("## âš™ï¸ Agent Configuration")
            
            # LLM Configuration
            llm_model = gr.Textbox(
                label="Model Name",
                value="QWQ-32B",
                placeholder="e.g., gpt-4o, claude-3-5-sonnet-20241022, llama3:8b",
                info="The model name to use"
            )
            
            source = gr.Dropdown(
                label="Source Provider",
                choices=["Auto-detect", "OpenAI", "Anthropic", "Gemini", "Ollama", "Custom"],
                value="OpenAI",
                info="Choose the model provider (Auto-detect will infer from model name)"
            )
            
            base_url = gr.Textbox(
                label="Base URL (Optional)",
                value="http://10.49.60.23:8684/v1",
                placeholder="e.g., https://api.openai.com/v1 or http://localhost:8000/v1",
                info="Custom API endpoint URL. Leave empty for default."
            )
            
            api_key = gr.Textbox(
                label="API Key (Optional)",
                value="token-abc123",
                placeholder="Enter your API key",
                type="password",
                info="API key for the service. Can also be set via environment variables."
            )
            
            data_path = gr.Textbox(
                label="Data Path",
                value="./data",
                placeholder="./data",
                info="Path where Biomni data will be stored"
            )
            
            verbose = gr.Checkbox(
                label="Enable Verbose Logging",
                value=True,
                info="Show detailed progress logs during execution (recommended for debugging)"
            )
            
            # Control buttons
            with gr.Row():
                create_btn = gr.Button("ğŸš€ Create Agent", variant="primary")
                reset_btn = gr.Button("ğŸ”„ Reset Agent", variant="secondary")
            
            # Status display
            status_text = gr.Textbox(
                label="Status",
                interactive=False,
                lines=2
            )
            
            config_info = gr.Textbox(
                label="Current Configuration",
                interactive=False,
                lines=4
            )
            
        with gr.Column(scale=3):
            gr.Markdown("## ğŸ’¬ Chat with Biomni")
            
            # Chat interface
            question = gr.Textbox(
                label="Your Question",
                placeholder="Ask Biomni to run a biomedical task...",
                lines=3
            )
            
            # Control buttons
            with gr.Row():
                ask_btn = gr.Button("ğŸ¤– Ask Biomni", variant="primary", scale=2)
                stop_btn = gr.Button("â¹ï¸ Stop", variant="stop", scale=1)
            
            # Status indicator
            status = gr.Textbox(
                label="Status",
                value="Ready",
                interactive=False,
                lines=1
            )
            
            # Multiple output areas
            with gr.Tab("Output"):
                intermediate_results = gr.HTML(
                    label="Output & Execution Steps",
                    value="<div style='text-align: center; color: #666; padding: 20px;'>Output will appear here...</div>",
                    elem_classes=["intermediate-results"]
                )
            
            with gr.Tab("Execution Log"):
                execution_log = gr.Textbox(
                    label="Detailed Execution Log",
                    lines=30,
                    interactive=False,
                    placeholder="Detailed execution logs will appear here..."
                )
            
            # Examples
            gr.Markdown("### ğŸ“ Example Questions:")
            gr.Examples(
                examples=[
                    "Plan a CRISPR screen to identify genes that regulate T cell exhaustion",
                    "Predict ADMET properties for this compound: CC(C)CC1=CC=C(C=C1)C(C)C(=O)O",
                    "Analyze the relationship between BRCA1 mutations and breast cancer risk",
                    "Generate a list of potential drug targets for Alzheimer's disease"
                ],
                inputs=question
            )
    
    # Event handlers
    # åˆ›å»ºagentæ—¶åˆ†é…æ–°çš„ä¼šè¯ID
    def create_agent_with_new_session(llm_model, source, base_url, api_key, data_path, verbose, session_id):
        """åˆ›å»ºagentæ—¶åˆ†é…æ–°çš„ä¼šè¯ID"""
        # æ€»æ˜¯ç”Ÿæˆæ–°çš„ä¼šè¯ID
        new_session_id = get_timestamp_session_id()
        print(f"[LOG] åˆ›å»ºagentæ—¶åˆ†é…æ–°ä¼šè¯ID: {new_session_id}")  # æ·»åŠ æ—¥å¿—
        result = create_agent(llm_model, source, base_url, api_key, data_path, verbose, new_session_id)
        # æ›´æ–°ä¼šè¯çŠ¶æ€
        session_status_text = f"Agent created for session: {new_session_id}"
        return result[0], result[1], new_session_id, session_status_text
    
    create_btn.click(
        fn=create_agent_with_new_session,
        inputs=[llm_model, source, base_url, api_key, data_path, verbose, session_display],
        outputs=[status_text, config_info, session_display, session_status]
    )
    
    reset_btn.click(
        fn=reset_agent,
        inputs=[session_display],
        outputs=[status_text, config_info]
    )
    
    # Stop button
    stop_btn.click(
        fn=stop_execution,
        inputs=[session_display],
        outputs=[intermediate_results, execution_log]
    )
    
    # Streaming ask function
    ask_btn.click(
        fn=ask_biomni_stream,
        inputs=[question, session_display],
        outputs=[intermediate_results, execution_log]
    )
    
    # Also allow Enter key to submit question
    question.submit(
        fn=ask_biomni_stream,
        inputs=[question, session_display],
        outputs=[intermediate_results, execution_log]
    )

if __name__ == "__main__":
    demo.queue(default_concurrency_limit=5, max_size=20)
    demo.launch(server_name="0.0.0.0", server_port=7860, share=False) 